{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from textblob import TextBlob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Sentiment Analysis example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').\\\n",
    "                               options(header='true', \\\n",
    "                               inferschema='true').\\\n",
    "            load(\"../twitter/stream_covid-19.csv\",header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338798\n",
      "+-------------------+--------------+-------------------+---------------+-----+--------------------+--------------------+\n",
      "|         twitter_id|          name|         created_at|followers_count|place|                text|      text_processed|\n",
      "+-------------------+--------------+-------------------+---------------+-----+--------------------+--------------------+\n",
      "|1247396599128420353|logicalindianz|2020-04-07 05:31:39|           5453| null|'RT @ANI: My neig...|my neighbours hav...|\n",
      "|1247396603029151746| N8V_Calgarian|2020-04-07 05:31:40|           5164| null|'RT @siiamhamilto...|the rcmp surround...|\n",
      "|1247396604534874112|      kk131066|2020-04-07 05:31:40|          15830| null|'RT @kk131066: Th...|the brains of gop...|\n",
      "|1247396608116957184|     drjulie_b|2020-04-07 05:31:41|           9315| null|'These R0 numbers...|these numbers are...|\n",
      "|1247396611526987777|        DArm91|2020-04-07 05:31:42|           5669| null|'RT @WuTangClan: ...|we got you just m...|\n",
      "+-------------------+--------------+-------------------+---------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (df.count())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@[A-Za-z0-9_]+|https?://[^ ]+|^.RT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "pat3 = r'^.RT'\n",
    "hashtag = r'\\#\\S*'\n",
    "combined_pat = r'|'.join((pat1, pat2, pat3))\n",
    "print(combined_pat)\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z19]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "text_process_udf = udf(tweet_cleaner_updated, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "sentiment_analysis_udf = udf(sentiment_analysis , FloatType())\n",
    "\n",
    "def condition(r):\n",
    "    if (r >=0.1):\n",
    "        label = \"positive\"\n",
    "    elif(r <= -0.1):\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    return label\n",
    "\n",
    "sentiment_udf = udf(lambda x: condition(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "df = df.withColumn('text_processed',text_process_udf(df['text']))\n",
    "df  = df.withColumn(\"sentiment_score\", sentiment_analysis_udf( df['text_processed'] ))\n",
    "df  = df.withColumn(\"sentiment\", sentiment_udf( df['sentiment_score'] ))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
